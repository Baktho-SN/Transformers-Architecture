{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multihead-attention"
      ],
      "metadata": {
        "id": "1kOqgAVUHiPK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing required libraries"
      ],
      "metadata": {
        "id": "E6bOfcH_C78G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ie_GvmAYB6cX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 4                                 # \"My name is Baktho\", 4 letters o sequence length is 4\n",
        "batch_size = 1                                 # just a single sentence so one batch\n",
        "input_dim = 512                                # each vector will be of 512 x 1 dimensions\n",
        "d_model = 512                                  # output of the attention unit\n",
        "x = torch.randn( ( batch_size, seq_length, input_dim  ) )"
      ],
      "metadata": {
        "id": "8_v3U9YyHv-O"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmHQmdHwIJFU",
        "outputId": "0bb5ff34-423e-4532-d96e-c3cb33b4e66e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qkv_layer = nn.Linear(input_dim, 3 * d_model)  # to concatenate query vec,key vec and Value vector"
      ],
      "metadata": {
        "id": "N5nI0byrILSt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qkv = qkv_layer(x)                             # pass through this layer to generate the qkv vector"
      ],
      "metadata": {
        "id": "acZmEPZKIRt3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qkv.shape                                      # 1 sentence, 4 sequence length and q,k,v vecs of each 512 dims so a total of 1536 dims"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOr4MenzIU2w",
        "outputId": "4803f701-b96a-4416-a3f2-69873be2da29"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 1536])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "y_val = torch.histc(qkv, bins = 200, min = -3, max = 3)\n",
        "x_val = np.arange(-1,1,0.01)*3\n",
        "plt.bar(x_val,y_val,align = \"center\", color = ['forestgreen']) # will be a random normal dist\n",
        "plt.title('qkv distribution')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "L5IlajDkKmpz",
        "outputId": "411a4039-2174-4a64-c89d-7ad996c3de66"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'qkv distribution')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_heads = 8                    # number of attention units/heads\n",
        "head_dim = d_model//num_heads    # each will be 512/8 = 64\n",
        " # breakdown last dimension by 8 (cuz 8 attention heads) and 3*head_dims cuz q,k,v(=3)\n",
        "qkv = qkv.reshape(batch_size,seq_length,num_heads,3 * head_dim)"
      ],
      "metadata": {
        "id": "1ZGtnXzoLJDR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qkv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "as5HAc4AMaYU",
        "outputId": "9e177974-df64-4bc5-b2c4-637f95ec180d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 8, 192])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qkv = qkv.permute(0,2,1,3)        # switching 2nd and 3rd dims so itll be easier to perform parellel operations on last two dimensions\n",
        "qkv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiAXNGAJMbh-",
        "outputId": "662ef823-628d-4483-d61a-e09e8986fc4b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 192])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q,k,v = qkv.chunk(3,dim=-1)       # breaking down the tensor into q,k,v by the last dim, thus dim=-1\n",
        "q.shape,k.shape,v.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytMuahZyMgxw",
        "outputId": "41895e9f-df2d-419b-f557-1a55bb5c6fcf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 8, 4, 64]),\n",
              " torch.Size([1, 8, 4, 64]),\n",
              " torch.Size([1, 8, 4, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Self attention for multiple heads\n",
        "\n",
        "<h4>self attention ( for single head ) </h4>\n",
        " =\n",
        "<br> <h3> softmax((Q.Kᵀ ÷ √dk) + M)V </h3>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HGiMlfuVNDbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d_k = q.shape[-1]\n",
        "\n",
        "'''\n",
        "since these are 4 dimensional tensors u cant use '.T' we have to specifiy along what dimensions\n",
        "do we want the tensor to be transposed, here -2,-1\n",
        "(This is why we used permute funcion to switch 2nd and 3rd column - seq_length and head_dim - previously)\n",
        "'''\n",
        "\n",
        "scaled = torch.matmul(q,k.transpose(-2,-1))/math.sqrt(d_k)   # scaling to reduce variance\n",
        "\n",
        "# basically a 4x4 matrix - seq_length x seq_length\n",
        "scaled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj3YWMm4M5et",
        "outputId": "b8cb9826-58b4-4f95-e8a4-38af8c8cb84e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k.T.shape                                      # small example for why we didnt use .T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFiC2QLVNa8X",
        "outputId": "a3e6d652-e475-4b88-8b8c-9a67700de267"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-879c2705464e>:1: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3614.)\n",
            "  k.T.shape\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 4, 8, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k.transpose(-2,-1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAuAQSnmNmgX",
        "outputId": "ad126d30-0b30-4843-fbbd-be54b59a2ed5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 64, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.full(scaled.size(), float('-inf')) # triangular matrix\n",
        "mask = torch.triu(mask,diagonal = 1)\n",
        "mask[0][1]                                      # this is to make sure the decoder doesnt cheat by using future words to predict present words,unnecessary for encoders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtrCRB6UNwGT",
        "outputId": "3045747f-1a00-44e4-c2a7-50c6e4f6aabc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., -inf, -inf, -inf],\n",
              "        [0., 0., -inf, -inf],\n",
              "        [0., 0., 0., -inf],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled+=mask"
      ],
      "metadata": {
        "id": "0pn0udF7OQE_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention = F.softmax(scaled,dim=-1)             # dim = -1 cuz the tensors will be in the last dim"
      ],
      "metadata": {
        "id": "8S_g3SufOf4C"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UJW1SqEOx_Q",
        "outputId": "e37d6581-a64a-4319-eead-f5b1e2ca268e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention[0][0]                                 # every row adds up to 1, why? Probabilitieess\n",
        "# this 4x4 attention matrix tells us how much a word is related to another in the sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7im-JmzdPFlO",
        "outputId": "8ddc1bc3-3a2e-48fe-924a-17d70fc1837b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.4716, 0.5284, 0.0000, 0.0000],\n",
              "        [0.3850, 0.3798, 0.2353, 0.0000],\n",
              "        [0.1707, 0.3634, 0.1008, 0.3651]], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values = torch.matmul(attention, v)\n",
        "values.shape                                    # this value vector will be comparatively much more context aware\n",
        "# we end up with a 64 dim vector for every sequence for every head for every batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQArxsXAPJrB",
        "outputId": "306d7777-553f-42d8-e0da-88c58052bd3d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function"
      ],
      "metadata": {
        "id": "9up7BsoFPUZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Just combine all the above code and make it into a function\n",
        "# this will be a single self attention head\n",
        "\n",
        "def scaled_dot_product(q,k,v, mask = None):     # mask = none for encoders, mask = mask for decoders\n",
        "  d_k = q.size()[-1]\n",
        "  mm = torch.matmul(q,k.transpose(-2,-1))\n",
        "  scaled = mm/math.sqrt(d_k)\n",
        "  if mask is not None:\n",
        "    scaled = scaled+mask\n",
        "  attention = F.softmax(scaled, dim = -1)\n",
        "  output = torch.matmul(attention,v)\n",
        "  return output, attention"
      ],
      "metadata": {
        "id": "9uUZVaRyPSOJ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values, attention = scaled_dot_product(q,k,v, mask=mask)\n",
        "print(\"Q\\n\",q,\"\\nK\\n\",k,\"\\nV\\n\",v)\n",
        "print(\"Values\\n\",values,\"\\nAttention\\n\",attention)"
      ],
      "metadata": {
        "id": "189WFF23PuXT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11298bbf-bd3e-4dce-c660-e8b0cb8d57a6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q\n",
            " tensor([[[[-0.1301,  0.0857,  0.3779,  ..., -0.0284, -0.0527, -0.6084],\n",
            "          [-0.5142,  0.5295, -0.0208,  ...,  0.3907, -0.8274,  0.0957],\n",
            "          [ 0.0505,  0.8751,  0.1564,  ..., -0.7117, -0.4734, -0.1008],\n",
            "          [-0.1558,  0.6907, -0.0031,  ...,  0.3236,  0.3047, -0.0852]],\n",
            "\n",
            "         [[ 0.1465, -0.3487,  0.4665,  ..., -0.6269,  1.0690,  0.0246],\n",
            "          [-0.3476, -1.2640,  0.6492,  ..., -0.2441, -0.9075, -0.2408],\n",
            "          [-0.1760,  0.5984,  0.9004,  ..., -0.5723, -0.9885,  0.4817],\n",
            "          [-0.5915,  0.7103,  0.0720,  ...,  0.5368, -0.9781,  0.5937]],\n",
            "\n",
            "         [[-0.5599,  0.0911, -0.2061,  ..., -0.0687, -0.8808, -1.2963],\n",
            "          [-0.1329, -0.9496,  0.3451,  ..., -0.9996,  0.9164,  0.5029],\n",
            "          [-0.1827,  0.0301, -0.2805,  ..., -0.7398,  0.4927,  1.1685],\n",
            "          [-0.2519, -0.0885, -0.3672,  ..., -0.6303,  1.0358,  0.0494]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.3826, -0.1644, -0.4895,  ...,  0.2282, -0.6658,  0.4612],\n",
            "          [-0.6635,  1.7157, -0.1362,  ...,  0.3737,  0.0411, -0.2279],\n",
            "          [ 0.1229,  0.1837,  0.4708,  ..., -0.3194,  0.2366,  0.4521],\n",
            "          [ 0.5046,  0.4825, -0.7043,  ..., -0.5163, -0.6824,  0.0639]],\n",
            "\n",
            "         [[ 0.5767, -0.1413,  0.0846,  ..., -0.0220, -0.3753, -1.1956],\n",
            "          [ 0.0310,  0.4445, -0.1211,  ...,  0.5121, -0.5484, -0.2760],\n",
            "          [-0.4970,  0.0895, -0.2137,  ...,  1.4042,  0.9438, -0.5531],\n",
            "          [-0.4880, -0.2332,  1.3820,  ..., -0.8128,  0.7489, -0.9454]],\n",
            "\n",
            "         [[ 0.1910, -0.9291,  0.2544,  ...,  0.0915,  0.5959, -0.1091],\n",
            "          [-0.3861, -0.5268, -0.4361,  ...,  0.4018,  0.1870,  0.5034],\n",
            "          [-0.3517,  0.9003,  0.2602,  ..., -0.8041,  0.1926,  0.1575],\n",
            "          [-0.1760,  0.0043, -0.5565,  ..., -0.6780,  0.1425, -0.1405]]]],\n",
            "       grad_fn=<SplitBackward0>) \n",
            "K\n",
            " tensor([[[[ 0.2512,  0.1917,  1.2466,  ...,  0.1790,  0.3193,  0.1534],\n",
            "          [ 0.3492,  0.3083,  0.0541,  ..., -0.5371, -0.7821, -0.5997],\n",
            "          [ 0.7284,  0.7146,  0.4072,  ..., -0.1909,  0.3667, -0.8804],\n",
            "          [ 0.0099, -0.2478,  0.3651,  ...,  0.2863, -0.9093,  0.8676]],\n",
            "\n",
            "         [[ 0.3998,  0.2728,  0.5005,  ..., -0.7906,  0.9486,  0.4153],\n",
            "          [-0.5902, -1.0270, -0.1511,  ..., -0.2160,  0.7419,  0.4261],\n",
            "          [ 0.1191,  0.2802, -0.0344,  ..., -0.4260,  0.6217,  0.5546],\n",
            "          [ 0.2842,  0.7360,  0.2878,  ...,  0.0275, -0.0234, -0.9445]],\n",
            "\n",
            "         [[-0.1391, -0.0741,  0.8217,  ...,  0.2037,  0.8128,  1.0432],\n",
            "          [-0.0378, -0.4600, -0.8267,  ..., -0.6404, -0.4500,  0.8650],\n",
            "          [ 0.1801,  0.2938, -0.0638,  ...,  0.5496, -1.1559, -0.0724],\n",
            "          [ 0.0174,  0.0256,  0.0419,  ..., -0.2558, -0.3016, -0.5297]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1281,  0.5853, -0.1753,  ...,  0.0306,  0.0039,  0.9574],\n",
            "          [-0.1396,  0.1041,  0.1003,  ...,  0.3311,  0.0959,  1.3524],\n",
            "          [ 0.0853, -0.5978,  0.4311,  ...,  0.5003, -0.5919,  0.5784],\n",
            "          [ 1.2178, -0.1467,  0.8618,  ...,  0.4010, -0.9733,  0.2326]],\n",
            "\n",
            "         [[ 0.4536,  0.0539,  0.5797,  ..., -0.7283,  0.3659, -0.1727],\n",
            "          [-0.0754, -1.2806,  0.9201,  ...,  0.6207,  0.2909, -0.7042],\n",
            "          [ 0.0745, -0.7476,  0.1583,  ...,  0.2690, -1.1656, -0.4025],\n",
            "          [ 0.4567,  0.4807,  0.0494,  ..., -0.1317,  0.8798, -0.1751]],\n",
            "\n",
            "         [[-0.0373, -0.2302, -0.4908,  ..., -0.9140, -0.2334,  0.0136],\n",
            "          [ 0.3834, -0.1470, -0.4749,  ..., -0.2381, -0.3817, -0.8741],\n",
            "          [-0.8518,  0.6038, -0.0219,  ...,  0.5192, -0.4362,  0.6577],\n",
            "          [-0.2063,  0.4308, -0.0783,  ..., -0.3858,  0.0855, -0.4539]]]],\n",
            "       grad_fn=<SplitBackward0>) \n",
            "V\n",
            " tensor([[[[-1.4164,  0.0535, -0.1851,  ..., -0.1450, -0.5650,  0.1608],\n",
            "          [-0.1445, -0.1903,  0.4992,  ..., -0.8042, -0.1568, -0.7207],\n",
            "          [-0.1249,  0.4489,  0.4071,  ...,  0.7439,  0.0810, -0.9592],\n",
            "          [-0.5839,  0.5941,  0.0492,  ..., -0.1290,  0.3951,  0.2202]],\n",
            "\n",
            "         [[-0.2578,  0.4249, -0.1138,  ...,  0.5582, -0.6842, -0.5906],\n",
            "          [ 0.0749,  0.5551,  0.8033,  ...,  0.0200, -0.3221, -0.3846],\n",
            "          [ 0.8767, -0.2315,  0.6285,  ..., -0.0640, -0.6373, -0.7116],\n",
            "          [ 0.5110, -0.0541,  0.8192,  ..., -0.3072, -0.2904,  0.2611]],\n",
            "\n",
            "         [[-0.1697,  0.0190,  0.2577,  ..., -0.7374,  0.1855,  0.4657],\n",
            "          [ 0.0246, -0.1710,  0.5494,  ...,  0.6681,  0.3300, -1.4559],\n",
            "          [ 0.4023, -0.6407,  0.4784,  ..., -0.7962, -0.0460, -0.7086],\n",
            "          [-0.2466, -0.1374,  0.4374,  ..., -0.3100, -0.1764, -0.1614]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1221,  0.9716,  0.2646,  ..., -0.0041, -0.5680,  0.3232],\n",
            "          [-0.5574, -0.2867,  0.4510,  ..., -0.7151, -0.7323, -0.0228],\n",
            "          [-0.2520, -0.4155, -0.2740,  ...,  0.5027,  0.2646, -0.0879],\n",
            "          [-0.8343, -0.0938, -0.3929,  ..., -1.1679, -0.4375, -0.4432]],\n",
            "\n",
            "         [[-0.4164, -0.2053, -0.2597,  ..., -0.6233, -0.3930, -0.2371],\n",
            "          [-0.9653,  1.1674,  0.2806,  ...,  0.0182, -0.0255, -0.6913],\n",
            "          [-1.1464,  0.2814,  0.4473,  ..., -0.4469, -0.0857, -0.0334],\n",
            "          [ 1.2155,  0.5358, -0.0964,  ..., -0.9328, -0.4035, -0.2047]],\n",
            "\n",
            "         [[ 0.2086,  1.1760,  0.9468,  ...,  0.1602, -0.8509,  0.4053],\n",
            "          [ 0.3248, -0.4911, -0.1564,  ..., -0.0435,  0.9738,  0.3835],\n",
            "          [-0.4656,  0.6002, -0.8254,  ..., -0.2725, -1.0653,  0.0755],\n",
            "          [ 0.3616,  0.0808,  0.5000,  ...,  0.0649,  0.6520,  0.3319]]]],\n",
            "       grad_fn=<SplitBackward0>)\n",
            "Values\n",
            " tensor([[[[-1.4164e+00,  5.3542e-02, -1.8509e-01,  ..., -1.4503e-01,\n",
            "           -5.6499e-01,  1.6076e-01],\n",
            "          [-7.4437e-01, -7.5278e-02,  1.7644e-01,  ..., -4.9331e-01,\n",
            "           -3.4934e-01, -3.0495e-01],\n",
            "          [-6.2952e-01,  5.3968e-02,  2.1408e-01,  ..., -1.8621e-01,\n",
            "           -2.5802e-01, -4.3746e-01],\n",
            "          [-5.2004e-01,  2.0214e-01,  2.0881e-01,  ..., -2.8915e-01,\n",
            "           -1.0281e-03, -2.5077e-01]],\n",
            "\n",
            "         [[-2.5778e-01,  4.2485e-01, -1.1383e-01,  ...,  5.5817e-01,\n",
            "           -6.8424e-01, -5.9062e-01],\n",
            "          [-1.0801e-01,  4.8348e-01,  2.9908e-01,  ...,  3.1587e-01,\n",
            "           -5.2121e-01, -4.9787e-01],\n",
            "          [ 2.6899e-01,  2.1635e-01,  4.3949e-01,  ...,  1.6315e-01,\n",
            "           -5.5855e-01, -5.7475e-01],\n",
            "          [ 2.7685e-01,  2.0630e-01,  5.4065e-01,  ...,  6.1812e-02,\n",
            "           -4.7872e-01, -3.7428e-01]],\n",
            "\n",
            "         [[-1.6965e-01,  1.9044e-02,  2.5765e-01,  ..., -7.3735e-01,\n",
            "            1.8553e-01,  4.6573e-01],\n",
            "          [-4.2197e-02, -1.0565e-01,  4.4910e-01,  ...,  1.8488e-01,\n",
            "            2.8033e-01, -7.9524e-01],\n",
            "          [-6.6136e-03, -1.5386e-01,  4.1718e-01,  ..., -1.1900e-01,\n",
            "            2.1894e-01, -5.4756e-01],\n",
            "          [-7.4877e-02, -1.2239e-01,  3.7982e-01,  ..., -3.4125e-01,\n",
            "            1.3555e-01, -2.1766e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1221e+00,  9.7157e-01,  2.6463e-01,  ..., -4.1289e-03,\n",
            "           -5.6804e-01,  3.2317e-01],\n",
            "          [ 1.6223e-01,  2.5245e-01,  3.7112e-01,  ..., -4.1043e-01,\n",
            "           -6.6191e-01,  1.2542e-01],\n",
            "          [ 1.4091e-01,  1.2419e-01,  1.5651e-01,  ..., -7.7706e-02,\n",
            "           -3.6037e-01,  8.0857e-02],\n",
            "          [ 1.2989e-01,  2.7397e-01,  1.3393e-01,  ..., -3.8707e-01,\n",
            "           -5.0831e-01,  3.3942e-02]],\n",
            "\n",
            "         [[-4.1641e-01, -2.0526e-01, -2.5967e-01,  ..., -6.2327e-01,\n",
            "           -3.9296e-01, -2.3710e-01],\n",
            "          [-7.4753e-01,  6.2275e-01,  6.6264e-02,  ..., -2.3633e-01,\n",
            "           -1.7130e-01, -5.1106e-01],\n",
            "          [-7.7783e-01,  3.3555e-01,  9.2969e-02,  ..., -3.8439e-01,\n",
            "           -2.0021e-01, -3.1714e-01],\n",
            "          [ 2.7754e-03,  5.3224e-01,  4.7254e-02,  ..., -5.5268e-01,\n",
            "           -2.5700e-01, -3.1924e-01]],\n",
            "\n",
            "         [[ 2.0861e-01,  1.1760e+00,  9.4680e-01,  ...,  1.6022e-01,\n",
            "           -8.5094e-01,  4.0531e-01],\n",
            "          [ 2.5931e-01,  4.4852e-01,  4.6540e-01,  ...,  7.1338e-02,\n",
            "           -5.4687e-02,  3.9579e-01],\n",
            "          [-1.1356e-01,  5.7674e-01, -1.5852e-01,  ..., -9.7637e-02,\n",
            "           -6.2537e-01,  2.3326e-01],\n",
            "          [ 1.8948e-01,  2.4923e-01,  2.1382e-01,  ...,  4.3806e-03,\n",
            "            1.3646e-01,  3.2383e-01]]]], grad_fn=<UnsafeViewBackward0>) \n",
            "Attention\n",
            " tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.4716, 0.5284, 0.0000, 0.0000],\n",
            "          [0.3850, 0.3798, 0.2353, 0.0000],\n",
            "          [0.1707, 0.3634, 0.1008, 0.3651]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.5498, 0.4502, 0.0000, 0.0000],\n",
            "          [0.3249, 0.2983, 0.3769, 0.0000],\n",
            "          [0.2449, 0.3039, 0.2370, 0.2141]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.3438, 0.6562, 0.0000, 0.0000],\n",
            "          [0.4207, 0.4456, 0.1337, 0.0000],\n",
            "          [0.4923, 0.2365, 0.1074, 0.1638]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.6364, 0.3636, 0.0000, 0.0000],\n",
            "          [0.3312, 0.4322, 0.2366, 0.0000],\n",
            "          [0.2214, 0.2238, 0.2710, 0.2838]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.5965, 0.4035, 0.0000, 0.0000],\n",
            "          [0.2836, 0.3581, 0.3583, 0.0000],\n",
            "          [0.4189, 0.1418, 0.2545, 0.1847]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.4285, 0.5715, 0.0000, 0.0000],\n",
            "          [0.3587, 0.3273, 0.3140, 0.0000],\n",
            "          [0.4248, 0.2798, 0.0956, 0.1997]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.3968, 0.6032, 0.0000, 0.0000],\n",
            "          [0.4310, 0.2979, 0.2711, 0.0000],\n",
            "          [0.1889, 0.2699, 0.1337, 0.4075]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
            "          [0.5636, 0.4364, 0.0000, 0.0000],\n",
            "          [0.3070, 0.1835, 0.5095, 0.0000],\n",
            "          [0.2280, 0.2814, 0.1534, 0.3372]]]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxBD3m_IP-2F",
        "outputId": "c8c83a30-cddb-4413-fa00-a91f85196a78"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urOpqMZPQBiX",
        "outputId": "9582b003-bf44-4c22-d0be-ea3192a78c85"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.4716, 0.5284, 0.0000, 0.0000],\n",
              "        [0.3850, 0.3798, 0.2353, 0.0000],\n",
              "        [0.1707, 0.3634, 0.1008, 0.3651]], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI58yFOhQFpT",
        "outputId": "b9aca821-779a-44df-87cc-7aa233eb9859"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values = values.reshape(batch_size,seq_length,num_heads * head_dim)\n",
        "values.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "l9l1x_RAQG8C",
        "outputId": "a00e0aaf-1c23-4dd4-e070-98013ab299a6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "shape '[30, 5, 512]' is invalid for input of size 2048",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-5b3a843d0f87>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_heads\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[30, 5, 512]' is invalid for input of size 2048"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_layer = nn.Linear(d_model,d_model)\n",
        "out = linear_layer(values)\n",
        "out"
      ],
      "metadata": {
        "id": "k-0MCBmMQTwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size,seq_length,num_heads,3 * head_dim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fsQHLJmQe5z",
        "outputId": "fde50db6-2067-455b-dcfe-d9a03c95b569"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 5, 8, 192)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Function"
      ],
      "metadata": {
        "id": "gCc1awS9Qlin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# now we combine all the code create a multiheaded attention class for, well multihead attention mechanism\n",
        "# simply put multihead attention = multiple single headed attention whose outputs are concatenated together\n",
        "\n",
        "def scaled_dot_product(q,k,v, mask = None):\n",
        "  d_k = q.size()[-1]\n",
        "  mm = torch.matmul(q,k.transpose(-2,-1))\n",
        "  scaled = mm/math.sqrt(d_k)\n",
        "  if mask is not None:\n",
        "    scaled = scaled+mask\n",
        "  attention = F.softmax(scaled, dim = -1)\n",
        "  output = torch.matmul(attention,v)\n",
        "  return output, attention\n",
        "\n",
        "class MultiheadAttention(nn.Module):\n",
        "  def __init__(self,input_dim,d_model,num_heads):\n",
        "    super().__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.d_model = d_model\n",
        "    self.num_heads = num_heads\n",
        "    self.head_dim = d_model // num_heads\n",
        "    self.qkv_layer = nn.Linear(input_dim,3*d_model)\n",
        "    self.linear_layer = nn.Linear(d_model,d_model)\n",
        "\n",
        "  def forward(self,x,mask=None):\n",
        "\n",
        "    batch_size,sequence_length,input_dim=x.size()\n",
        "    print(f\"x.size():{x.size()}\")\n",
        "\n",
        "    qkv = self.qkv_layer(x)\n",
        "    print(f\"qkv.size():{qkv.size()}\")\n",
        "\n",
        "    qkv = qkv.reshape(batch_size,seq_length,self.num_heads,3 * self.head_dim)\n",
        "    print(f\"qkv.size():{qkv.size()}\")\n",
        "\n",
        "    qkv = qkv.permute(0,2,1,3)\n",
        "    print(f\"qkv.size():{qkv.size()}\")\n",
        "\n",
        "    q,k,v = qkv.chunk(3,dim=-1)\n",
        "    print(f\"q.size():{q.size()}, \\nk.size():{k.size()}, \\nv.size():{v.size()}\")\n",
        "\n",
        "    values, attention = scaled_dot_product(q,k,v, mask=mask)\n",
        "    print(f\"values.size():{values.size()}, \\nattention.size():{attention.size()}\")\n",
        "\n",
        "    values = values.reshape(batch_size,seq_length,self.num_heads * self.head_dim)\n",
        "    print(f\"values.size():{values.size()}\")\n",
        "\n",
        "    out = self.linear_layer(values)\n",
        "    print(f\"out.size():{out.size()}\")\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "paJ6hyX3Qh84"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample\n",
        "seq_length = 5\n",
        "batch_size = 30\n",
        "input_dim = 1024\n",
        "d_model = 512\n",
        "num_heads = 8\n",
        "\n",
        "x = torch.randn( ( batch_size, seq_length, input_dim  ) )\n",
        "\n",
        "model = MultiheadAttention( input_dim,d_model,num_heads )\n",
        "out = model.forward(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbI9dMSqSqvC",
        "outputId": "9ce11490-b1c0-4725-a6da-524c9dede7f8"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.size():torch.Size([30, 5, 1024])\n",
            "qkv.size():torch.Size([30, 5, 1536])\n",
            "qkv.size():torch.Size([30, 5, 8, 192])\n",
            "qkv.size():torch.Size([30, 8, 5, 192])\n",
            "q.size():torch.Size([30, 8, 5, 64]), \n",
            "k.size():torch.Size([30, 8, 5, 64]), \n",
            "v.size():torch.Size([30, 8, 5, 64])\n",
            "values.size():torch.Size([30, 8, 5, 64]), \n",
            "attention.size():torch.Size([30, 8, 5, 5])\n",
            "values.size():torch.Size([30, 5, 512])\n",
            "out.size():torch.Size([30, 5, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v-_bnp8UTKqg"
      },
      "execution_count": 50,
      "outputs": []
    }
  ]
}